# Local RAG using LLAMA 3.2
## Chat with your own document
A free RAG implementation of QA 

### LLM infrastructure


```
LLM used: Llama 3.2 3b instruct                            
Embedding model: bge-small-en-v1.5                         
Vector store: Qdrant                                       
Workflow orchestration: Llama Index                        
RAG Technique: Re-ranking method [ms-marco-MiniLM-L-2-v2]  
```

To get started, try the implementation in below notebook

[link text](https://)

# Demo


