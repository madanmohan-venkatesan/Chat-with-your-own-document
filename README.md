# Local RAG using LLAMA 3.2
## Chat with your own document
A free RAG implementation of QA 

### LLM infrastructure


```
LLM used: Llama 3.2 3b instruct                            
Embedding model: bge-small-en-v1.5                         
Vector store: Qdrant                                       
Workflow orchestration: Llama Index                        
RAG Technique: Re-ranking method [ms-marco-MiniLM-L-2-v2]  
```

To get started, try the implementation in below notebook

[llama_rag_with_colab_demo.ipynb]([https://](https://github.com/madanmohan-venkatesan/Chat-with-your-own-document/blob/bcc48d39716507ca4bf0504c0da220367c4e7d94/llama_rag_with_colab_demo.ipynb))

# Demo


